{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a MLP to identify primary vertices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will calulate the primary vertex from simulated tracks in a detector produced from colliding bunches of protons. We assume that there is one hard proton-proton interaction in an event, at the point we call the primary vertex. These tracks are reconstructed from the hard proton-proton interaction and tend to have higher p<sub>T</sub> values. The majority of the tracks in the event are not from the hard proton-proton interaction, but are from soft proton-proton interactions (pileup) and typically have lower p<sub>T</sub>\n",
    "\n",
    "Lets simulate the data. There is no need to understand the details of the data simulation. All you need to know is that the interaction region spans from 0 to 1 in z where for each event there are tracks from pileup events uniformly distributed. For each event there is also a primary vertex at a random position in z which generates tracks around around this point with a higher p<sub>T</sub> distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def generateCollisonTracks(numEvents=10000):\n",
    "\n",
    "    maxTracks = 100\n",
    "    aveNumPrimaryVertexTracks = 10\n",
    "    stdNumPrimaryVertexTracks = 3\n",
    "    vertexResolution = 0.1\n",
    "    meanPrimaryTrackPt = 50\n",
    "    stdPrimaryTrackPt = 10\n",
    "    meanPileUpTrackPt = 10\n",
    "    stdPileUpTrackPt = 10\n",
    "\n",
    "    #Allocate memory for dataset\n",
    "    ds = np.zeros((numEvents,maxTracks,2))\n",
    "    primary_vertices = np.zeros((numEvents))\n",
    "\n",
    "    #Be suspicious of loops with libraries that employ vectorisation\n",
    "    # Not worried about poor performance here\n",
    "    for ievent in range(numEvents):\n",
    "        y = np.random.uniform(0.2,0.8)\n",
    "        numPrimaryVertexTracks = np.random.normal(aveNumPrimaryVertexTracks, stdNumPrimaryVertexTracks, 1).astype(int)[0]\n",
    "        \n",
    "        #We want at least 1 track\n",
    "        if numPrimaryVertexTracks < 1:\n",
    "            numPrimaryVertexTracks = 1\n",
    "            \n",
    "        primaryTracks_z = np.random.normal(y, vertexResolution, numPrimaryVertexTracks)\n",
    "        primaryTracks_pt = np.random.normal(meanPrimaryTrackPt, stdPrimaryTrackPt, numPrimaryVertexTracks)\n",
    "\n",
    "        #Numberof tracks from soft collision\n",
    "        numPileupTracks = maxTracks - numPrimaryVertexTracks\n",
    "\n",
    "        pileUpTracks_z = np.random.uniform(0.0,1.0, numPileupTracks)\n",
    "        pileUpTracks_pt = np.random.normal(meanPileUpTrackPt, stdPileUpTrackPt, numPileupTracks)\n",
    "\n",
    "        #Assign generated events to dataset\n",
    "        ds[ievent,:numPrimaryVertexTracks,0] =  primaryTracks_z[:]\n",
    "        ds[ievent,:numPrimaryVertexTracks,1] =  primaryTracks_pt[:]\n",
    "        ds[ievent,numPrimaryVertexTracks:,0] =  pileUpTracks_z[:]\n",
    "        ds[ievent,numPrimaryVertexTracks:,1] =  pileUpTracks_pt[:]\n",
    "\n",
    "        primary_vertices[ievent] = y\n",
    "\n",
    "        #Shuffle the tracks\n",
    "        shuffledIndex = np.arange(maxTracks)\n",
    "        np.random.shuffle(shuffledIndex)\n",
    "        ds[ievent] = ds[ievent,shuffledIndex]\n",
    "\n",
    "    return primary_vertices, ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data by calling the generateCollisonTracks function. This function returns an array with the postion of the primary vertex for each event (p_vtx) and an array with the track information for each event (z and p<sub>T</sub>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vtx, trackData = generateCollisonTracks(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function generateCollisonTracks generates 10000 events (or whatever number your request). Each event will consist of 100 arrays, each representing a track. Each track array holds 2 variables, the z value of the track extrapolated to the beam line and the p<sub>T</sub> associated with the track\n",
    "\n",
    "Take a look at the layout of the data using the .shape method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data itselt. Say the first event of the track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackData[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have the actual values of the primary vertex which we can train against. Look at the first 10 events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vtx[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the disribution of tracks in z. Not very informative just plotting the tracks in z. However you should see that the distribution is flat. There is a cluster of tracks around the primary vertex in there somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(trackData[0,:,0], bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use a simple MLP and train on the z and p<sub>T</sub> of the tracks using the trackData array to calculate the primary vertex found in the p_vtx array\n",
    "    \n",
    " First separate the data into a training, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTrainingIndex = 8000\n",
    "endValidationIndex = 9000\n",
    "\n",
    "#Split into training and validation samples\n",
    "data_train, data_val, data_test =  trackData[:endTrainingIndex], trackData[endTrainingIndex:endValidationIndex],trackData[endTrainingIndex:endValidationIndex]\n",
    "y_train, y_val , y_test =  p_vtx[:endTrainingIndex], p_vtx[endTrainingIndex:endValidationIndex], p_vtx[endTrainingIndex:endValidationIndex]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(100, 2)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss function and optimiser\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 400\n",
    "#Not worried about memory or local minima\n",
    "batchSize = len(data_train)\n",
    "\n",
    "#Train on data\n",
    "history = model.fit(data_train, y_train,\n",
    "          validation_data=(data_val, y_val),\n",
    "          batch_size=len(y_train),\n",
    "          epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
