{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training a Multi Layered Perceptron (MLP) using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a code cell, click on the cell the press \"Shift + Enter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow version 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "#Want to use version of Tensorflow > 2.0\n",
    "print('Using Tensorflow version %s' % tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a dataset, consisting of two data types which we call signal and background. Each data type is normally generated around a point in the x-y plane. Distinguishing signal from backgorund is a very simple problem. You could use PDFs and likelihoods identify signal and backgound. We will build a very simply MLP classifier to identify events as signal or background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datasets\n",
    "num_events = 10000\n",
    "\n",
    "#Signal x and y mean values\n",
    "signal_mean = [1.0, 1.0]\n",
    "#Signal x and y values are uncorrelated\n",
    "signal_cov = [[1.0, 0.0],\n",
    "              [0.0, 1.0]]\n",
    "\n",
    "#Generate a training and validation sample\n",
    "signal_train = np.random.multivariate_normal(\n",
    "        signal_mean, signal_cov, num_events)\n",
    "signal_val = np.random.multivariate_normal(\n",
    "        signal_mean, signal_cov, num_events)\n",
    "\n",
    "#Background x and y mean values\n",
    "background_mean = [-1.0, -1.0]\n",
    "#Background x and y values are uncorrelated\n",
    "background_cov = [[1.0, 0.0],\n",
    "                  [0.0, 1.0]]\n",
    "\n",
    "#Generate a training and validation sample\n",
    "background_train = np.random.multivariate_normal(\n",
    "        background_mean, background_cov, num_events)\n",
    "background_val = np.random.multivariate_normal(\n",
    "        background_mean, background_cov, num_events)\n",
    "\n",
    "#Add the signal and background samples\n",
    "data_train = np.vstack([signal_train, background_train])\n",
    "labels_train = np.vstack([np.ones((num_events, 1)), np.zeros((num_events, 1))])\n",
    "\n",
    "#Add the signal and background samples\n",
    "data_val = np.vstack([signal_val, background_val])\n",
    "labels_val = np.vstack([np.ones((num_events, 1)), np.zeros((num_events, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the datasets generated\n",
    "range_ = ((-3, 3), (-3, 3))\n",
    "plt.figure(0, figsize=(8,4))\n",
    "plt.subplot(1,2,1); plt.title(\"Signal\")\n",
    "plt.xlabel(\"x\"), plt.ylabel(\"y\")\n",
    "plt.hist2d(signal_train[:,0], signal_train[:,1],\n",
    "        range=range_, bins=20, cmap=cm.coolwarm)\n",
    "plt.subplot(1,2,2); plt.title(\"Background\")\n",
    "plt.hist2d(background_train[:,0], background_train[:,1],\n",
    "        range=range_, bins=20, cmap=cm.coolwarm)\n",
    "plt.xlabel(\"x\"), plt.ylabel(\"y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a simple problem we can build a simple MLP to identify signal and background events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use Tensorflows sequential API. We pass the layers to the API sequentially\n",
    "#Construct Neural Net\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\", input_dim=2))\n",
    "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to look at the architecture of your neural net to check it makes sense. Do you have the total number of parameters you would expect to have. Use the model's method .summary() to see a breakdown of your neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set loss function and optimiser. As this is a classification neural net we want to use binary cross entropy as the loss function. We will use adam as the optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss function and optimiser\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on data. Define the dataset you want to train on and the validation set you want to validate the training against. Set the number of epochs (the number of iterations over the dataset). Set the batch size. This is a number/size of events smaller than your dataset that you run over and update the weights of your neural net. You run over multiples of batch sizes until you have run over all your events in your dataset. That is one epoch.  The batch size can actually be quite important. A small batch size can be good if you are low on computer memory or want to avoid getting stuck in a local minima. Too small a batch size can make converging on optimal weighs slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "#Not worried about memory or local minima\n",
    "batchSize = len(data_train)\n",
    "\n",
    "#Train on data\n",
    "history = model.fit(data_train, labels_train,\n",
    "          validation_data=(data_val, labels_val),\n",
    "          batch_size=len(data_train),\n",
    "          epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92% accurracy. Not bad! Be careful with accuracy measurments. It is easy to measure high accuracy if your validation or test sample mainly has one category of data. Not the case here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss of the neural net as a function of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', color='red', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about saving the model. Also at what point do save the model. This is an ideal example where the loss is smooth and decreases monotonically. You'll find this is rarely the case. What I tend to do is save the model each time the validation loss reaches a minimum. You overtrain your neural net if you use the training loss as a metric for saving your model. Let's use a callback to save the model. A callback kets you specify a list of objects that will be called during training. We can use a callback to save the model every time the validation loss is at a minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Specify a directory to save model\n",
    "\n",
    "model_filename = 'simple_mlp.h5'\n",
    "saved_model_directory = 'models'\n",
    "\n",
    "checkpoint_filename = os.path.join(saved_model_directory, model_filename)\n",
    "\n",
    "CHECK_FOLDER = os.path.isdir(saved_model_directory)\n",
    "\n",
    "# If folder doesn't exist, then create it.\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(saved_model_directory)\n",
    "    print(\"created folder : \", saved_model_directory)\n",
    "                \n",
    "#Create checkpoint\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filename,\n",
    "        monitor='val_loss',\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        verbose = 1)\n",
    "\n",
    "        \n",
    "history = model.fit(data_train, labels_train,\n",
    "        validation_data=(data_val, labels_val),\n",
    "        batch_size=len(data_train),\n",
    "        epochs=num_epochs,\n",
    "        callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "\n",
    "model.load_weights(checkpoint_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification with a MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the MNIST dataset, famous in machine learning examples. Specifically we can look at images of handwritten numbers 0-9 and use a MLP to identify them. This is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. More info can be found at the <a id='http://yann.lecun.com/exdb/mnist'>MNIST homepage</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label is: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "# Randomly look at one of the images\n",
    "random_ints =np.random.randint(len(x_test), size=1)\n",
    "image_index = random_ints[0]\n",
    "\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "\n",
    "print('Image label is: %i' % y_test[image_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build an mlp to identify the images. The intenstiy of the pixels is represented as a value from 0 to 255. We should normalise the intensity. Also, the image is a 2D array so we should flatten it to a 1D array so the values can be input into a MLP. Lets build a simple MLP with a hidden layer containing 128 nodes and an output layer of 10 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Intensity of pixels ranges from 0-255. We need to normalise them\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "#Rather than instantiate the node and use the .add method to keep adding input,layers, outputs, etc we can just state\n",
    "#components separated by a comma during instantiation\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One would expect some kind of sigmoid activation function to be applied to the output. However we let the loss function SparseCategoricalCrossentropy take the output and use it to calculate the loss to best attribute probabilities to each output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2743 - accuracy: 0.9217 - val_loss: 0.1338 - val_accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.1221 - accuracy: 0.9638 - val_loss: 0.0925 - val_accuracy: 0.9734\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0832 - accuracy: 0.9753 - val_loss: 0.0828 - val_accuracy: 0.9760\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0628 - accuracy: 0.9814 - val_loss: 0.0776 - val_accuracy: 0.9780\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.0773 - val_accuracy: 0.9798\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.0379 - accuracy: 0.9882 - val_loss: 0.0838 - val_accuracy: 0.9772\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.0713 - val_accuracy: 0.9798\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.0924 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0789 - val_accuracy: 0.9808\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.0896 - val_accuracy: 0.9798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fec8fc08050>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split into training and validation samples\n",
    "x_train, x_val = x_train[0:55000], x_train[55000:]\n",
    "y_train, y_val = y_train[0:55000], y_train[55000:]\n",
    "num_epochs = 10\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99%, pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add sections on learning rate scheduling (default learning rate is 1e-2), dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
