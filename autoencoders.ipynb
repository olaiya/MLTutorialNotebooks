{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4571e9",
   "metadata": {},
   "source": [
    "# <center> Autoencoders </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e09817",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/olaiya/MLTutorialNotebooks/blob/master/autoencoders.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c0e6d",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- [0. Autoencoders](#0.) \n",
    "- [1. Setup](#1.)   \n",
    "- [2. Implementing a Stacked Autoencoder Using Keras](#2.)\n",
    "    - [2.1 Visualizing the Reconstructions](#2.1)\n",
    "- [3. Denoising Autoencoders](#3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079720a",
   "metadata": {},
   "source": [
    "## 0. Autoencoders <a name=\"0.\"></a>\n",
    "\n",
    "<img src=\"images/ae.png\" alt=\"autoencoder\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981cf93",
   "metadata": {},
   "source": [
    "An autoencoder is a type of artificial neural network used to learn efficient codings of unlabeled data (unsupervised learning). An autoencoder learns two functions: an encoding function that transforms the input data, and a decoding function that recreates the input data from the encoded representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11608592",
   "metadata": {},
   "source": [
    "## 1. Setup <a name=\"1.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c47ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ced1a6",
   "metadata": {},
   "source": [
    "Let's define the default font size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49b7e5",
   "metadata": {},
   "source": [
    "Let's create the images/generative folder (if it doesn't already exist), and define the save_fig() function to save the figures in high-res for the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"generative\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e4e9ad",
   "metadata": {},
   "source": [
    "## 2. Implementing a Stacked Autoencoder Using Keras <a name=\"2.\"></a>\n",
    "\n",
    "Let's load the fashion MNIST dataset, scale it, and split it into a training set, a validation set, and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – loads, scales, and splits the fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train_full = X_train_full.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a5bb4",
   "metadata": {},
   "source": [
    "Let's build and train a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87908a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "\n",
    "stacked_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "])\n",
    "stacked_decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(28 * 28),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])\n",
    "stacked_ae = tf.keras.Sequential([stacked_encoder, stacked_decoder])\n",
    "\n",
    "stacked_ae.compile(loss=\"mse\", optimizer=\"nadam\")     \n",
    "\n",
    "history = stacked_ae.fit(X_train, X_train, epochs=20,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec0237a",
   "metadata": {},
   "source": [
    "## Visualizing the Reconstructions <a name=\"2.1\"></a>\n",
    "\n",
    "This function processes a few validation images through the autoencoder and displays the original images and their reconstructions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructions(model, images=X_valid, n_images=5):\n",
    "    reconstructions = np.clip(model.predict(images[:n_images]), 0, 1)\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plt.imshow(images[image_index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plt.imshow(reconstructions[image_index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05988afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructions(stacked_ae)\n",
    "save_fig(\"reconstruction_plot\")  # extra code – saves the high res figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a5296",
   "metadata": {},
   "source": [
    "# 3. Denoising Autoencoders <a name=\"3.\"></a>\n",
    "\n",
    "Using dropout to remove information from the input. Then use an autoencoder to learn how to return the lost from the input. Essentially we will simply create an **image noise reduction algorithm** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fcede",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  #ensures reproducibility on CPU\n",
    "\n",
    "dropout_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5), #Drop half the weights at this point, ie. drop half the inputs\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "])\n",
    "dropout_decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(28 * 28),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])\n",
    "dropout_ae = tf.keras.Sequential([dropout_encoder, dropout_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaef376",
   "metadata": {},
   "source": [
    "Compile and train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_ae.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = dropout_ae.fit(X_train, X_train, epochs=10,\n",
    "                         validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d47914",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "dropout = tf.keras.layers.Dropout(0.5) #drop half the weights randomly, seed above make the results reproduceable\n",
    "plot_reconstructions(dropout_ae, dropout(X_valid, training=True)) # pass model and input x dropout\n",
    "save_fig(\"dropout_denoising_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b452332",
   "metadata": {},
   "source": [
    "Brilliant! Autoencode enables us to restore noisy image!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
