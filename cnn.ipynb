{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/olaiya/MLTutorialNotebooks/blob/master/cnn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- [1. Constructing a CNN with Tensorflow](#1.)\n",
    "    - [1.1 Import required libraries](#1.1)\n",
    "    - [1.2 Download MNIST dataset](#1.2)\n",
    "    - [1.3 Build, train and run a simple CNN](#1.3)\n",
    "    - [1.4 Loss and Accuracy](#1.4)\n",
    "    - [1.5 Image identification](#1.5)\n",
    "    - [1.6 Filter and feature maps](#1.6)\n",
    "- [2. CNN Classification using the CIFAR10 Dataset](#2.)\n",
    "    - [2.1 Download CIFAR10 dataset](#2.1)\n",
    "    - [2.2 Constructing a CNN for identifying CIFAR10 colour images](#2.2)\n",
    "    - [2.3 Evaluating the accuracy](#2.3)\n",
    "    - [2.4 More layers,less parameters](#2.4)\n",
    "    - [2.5 Evaluating the test sample](#2.5)\n",
    "    - [2.6 Generated filters](#2.6)\n",
    "- [2.7 Exercise: classification of the fashion MNIST dataset ](#3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Constructing a CNN with Tensorflow <a name=\"1.\"></a>\n",
    "\n",
    "Let's look at constructing a convolutional neural net. We can use the same MNIST number dataset we used with our mlp and classify the data using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import requied libraries <a name=\"1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "#Want to use version of Tensorflow > 2.0\n",
    "print('Using Tensorflow version %s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download MNIST dataset <a name=\"1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Intensity of pixels ranges from 0-255. We need to scale the values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the tf.keras.layers.Conv2D API\n",
    "#The 4 dims are , Num_of Events,image_height, image_width, num_of_channels\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "#Split into training and validation samples\n",
    "x_train, x_val = x_train[0:55000], x_train[55000:]\n",
    "y_train, y_val = y_train[0:55000], y_train[55000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Build, train and run a simple CNN <a name=\"1.3\"></a>\n",
    "\n",
    "Build a simple CNN. We will output a convolution layer using 14 different filters (kernels) of size 3x3 with no padding to the images. We will then apply a 3x3 max pooling filter to the convolutional later. The output we will then feed to a mlp with a hidden layer of 128 nodes and then feed that to an output layer of 10 nodes which we will apply the sofmax activation functions\n",
    "\n",
    "<img src=\"images/convLayers.png\" alt=\"mlp\" width=\"800\"/>\n",
    "\n",
    "<img src=\"images/filter.png\" alt=\"mlp\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sequential Model and adding the layers\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Conv2D(number_of_filters, kernel_size=(filter size), input_shape=(height, width, num_of_channels))\n",
    "    tf.keras.layers.Conv2D(14, kernel_size=(3,3), input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(3, 3)),\n",
    "    tf.keras.layers.Flatten(), # Flattening the 2D arrays for fully connected layers\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    #Don't need softmax here, softmax activation included in  the loss function\n",
    "    #tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "num_epochs = 20\n",
    "batchSize = 1000\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "          validation_data=(x_val, y_val),\n",
    "          batch_size=batchSize,\n",
    "          epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Loss and Accuracy <a name=\"1.4\"></a>\n",
    "\n",
    "Lets look at the loss distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', color='red', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_val,  y_val, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is high. Can you improve on it?\n",
    "\n",
    "### 1.5 Image identification <a name=\"1.5\"></a>\n",
    "\n",
    "Let's look at the test sample and see if we can correctly identify the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the images that were incorrectly identified. Use the .predict method to identify the images in the test sample. Execute the cell below to show some of the images that were incorrectly identified. You can change only_bad=False to show the images that were correctly identified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nr,nc=10,5\n",
    "only_bad=True\n",
    "plt.figure(figsize=(4*nc,2*nr))\n",
    "\n",
    "image_index,plot_index=-1,0\n",
    "npass,ntot=0,0\n",
    "while plot_index < nc*nr and image_index < len(x_test):\n",
    "    ntot += 1\n",
    "    image_index += 1\n",
    "    label = y_test[image_index]\n",
    "    prediction_outputs = list(y_test_prediction[image_index])\n",
    "    prediction = prediction_outputs.index(max(prediction_outputs))\n",
    "    if prediction == label:\n",
    "        npass += 1\n",
    "        if only_bad: continue\n",
    "    else:\n",
    "        print(\"image #%i: label = %i, prediction = %i\" % (image_index, label, prediction))\n",
    "    plot_index += 1\n",
    "    plt.subplot(nr,2*nc,plot_index)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "    plt.xlabel(\"%i\" % label)\n",
    "\n",
    "    plot_index += 1\n",
    "    plt.subplot(nr,2*nc,plot_index)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    col=['b']*10\n",
    "    col[label]='g'\n",
    "    col[prediction]='r'\n",
    "    plt.bar(range(10),prediction_outputs,width=1.0,color=col)\n",
    "    plt.xlabel(\"%i\" % prediction)\n",
    "\n",
    "print (\"failed = %d/%d, accuracy = %.4f%%\" % (ntot-npass,ntot,float(npass)/float(ntot)*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Filters and Feature maps <a name=\"1.6\"></a>\n",
    "\n",
    "Let's look at the filters the training produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10)) \n",
    "#Iterate through all layers\n",
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        weights, biases = layer.get_weights()\n",
    "        print(layer.name, weights.shape)\n",
    "        \n",
    "        #scale filters        \n",
    "        f_min, f_max = weights.min(), weights.max()\n",
    "        filters = (weights - f_min) /(f_max - f_min)\n",
    "        #iterate through all filters\n",
    "        for i in range(filters.shape[3]):\n",
    "            plt.subplot(2,7,i+1)\n",
    "            filt = filters[:,:,:,i]\n",
    "            #Select channel\n",
    "            #print(filt[:,:,0].shape)\n",
    "            filt_chan = filt[:,:,0]\n",
    "            plt.imshow(filt_chan,cmap='gray_r',vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the feature maps produced by the filters. Set up a model to visualise the filter maps. Take an image from the test sample to see how what its filter maps look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "#Use one of the test images\n",
    "\n",
    "img = x_test[0]\n",
    "\n",
    "#Display image we are going to run through our Convolutional Neural Net\n",
    "plt.imshow(img.reshape(28, 28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass image through model and view how the filter maps look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape image so it fits the input format\n",
    "img= img[np.newaxis, :,:,: ]\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(img)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "# -----------------------------------------------------------------------\n",
    "# Now let's display our representations\n",
    "# -----------------------------------------------------------------------\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    print(feature_map.shape)\n",
    "    if len(feature_map.shape) == 4:\n",
    "    \n",
    "        #-------------------------------------------\n",
    "        # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        #-------------------------------------------\n",
    "        n_features = feature_map.shape[-1]  # number of features in the feature map\n",
    "        size_y       = feature_map.shape[1]  # feature map shape (1, size_y, size_x, n_features)\n",
    "        size_x       = feature_map.shape[2]  # feature map shape (1, size_y, size_x, n_features)\n",
    "    \n",
    "        # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size_y, size_x * n_features))\n",
    "    \n",
    "        #-------------------------------------------------\n",
    "        # Postprocess the feature to be visually palatable\n",
    "        #-------------------------------------------------\n",
    "        for i in range(n_features):\n",
    "            x  = feature_map[0, :, :, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std ()\n",
    "            x *=  64\n",
    "            x += 128\n",
    "            x  = np.clip(x, 0, 255).astype('uint8')\n",
    "            display_grid[:, i * size_y : (i + 1) * size_x] = x # Tile each filter into a horizontal grid\n",
    "\n",
    "        #-----------------\n",
    "        # Display the grid\n",
    "        #-----------------\n",
    "\n",
    "        scale = 20. / n_features\n",
    "        plt.figure( figsize=(scale * n_features, scale) )\n",
    "        plt.title ( layer_name )\n",
    "        plt.grid  ( False )\n",
    "        plt.imshow( display_grid, aspect='auto', cmap='viridis' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN Classification using the CIFAR10 Dataset <a name=\"2.\"></a>\n",
    "\n",
    "Let's classify more images by taking the CIFAR10 dataset. The CIFAR10 dataset contains 60,000 colour images in 10 classes, with 6,000 images in each class. The classes are mutually exclusive, so there is no overlap between them. The dataset is divided into 50,000 training images and 10,000 testing images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Downloading the CIFAR10 Dataset <a name=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Scale pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training sample into training and validation samples\n",
    "train_images, val_images = train_images[0:45000], train_images[45000:]\n",
    "train_labels, val_labels = train_labels[0:45000], train_labels[45000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Constructing a CNN for identifying CIFAR10 colour images <a name=\"2.2\"></a>\n",
    "\n",
    "Our previous images were black and white but now we are working with colour images. This is straight forward, we can just feed the images into our CNN via their colour channels. The images are 32x32 pixels in size and have three colour channels (red,green,blue). So the shape of the images is 32, 32, 3\n",
    "\n",
    "Let's build a more sophisticated neural net with more convolutional layers. The first convolutional layer will have 32 output channels using a 3x3 filter (kernel) and then reduced in size using maxpooling. The second layer will have 64 output channels, also reduced in size with maxpooling and the final convolutional layer will have a output of 64 channels. We can then feed the output to a mlp with a layer containing 64 neurons and an output of 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Conv2D(number_of_filters, kernel_size=(filter size), input_shape=(height, width, num_of_channels))\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(), # Flattening the 2D arrays for fully connected layers\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', color='red', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate the accuracy <a name=\"2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 More layers, less parameters  <a name=\"2.4\"></a>\n",
    "\n",
    "Let's demonstrate the power of adding convolutional layers. Each convolutional layer has less information than the previous. Remember it is the final layer you feed into the mlp. So the smaller your final convolutional layer, the smaller and therefore the less parameters you have in your mlp. Of course you require filters (which require parameters) to generate convolutional layers, but the parameters required for the filters are typically more than compensated for by the reduced size of the required mlp. So the beauty of CNNs is that you can reduce the number of parameters required for your model and not necessarily reduce the performance. You can even improve the performance!\n",
    "\n",
    "Let's build a more sophisticated neural net with more convolutional layers. The first convolutional layer will have 32 output channels using a 3x3 filter (kernel) and then reduced in size using maxpooling 2x2 filter. The second layer will have 64 output channels using a 3x3 filter, also reduced in size with maxpooling 2x2 filter and the final concolutional layer will have a output of 64 channels using a 3x3 filter. We can then feed the output to a mlp with a layer containing 64 neurons and an output of 10 neurons. Build and run this CNN in the cells below. Use the comments as instructions. Compare the number of parameters of this CNN with the previous CNN and their accuracy profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Conv2D(number_of_filters, kernel_size=(filter size), input_shape=(height, width, num_of_channels))\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(), # Flattening the 2D arrays for fully connected layers\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=20, \n",
    "                    validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', color='red', label='Validation loss')\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.3, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Evaluating the test sample  <a name=\"2.5\"></a>\n",
    "\n",
    "Let's look at the test sample and see if we can correctly identify the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_prediction = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Generated filters  <a name=\"2.6\"></a>\n",
    "\n",
    "Let's look at some of the filters that were generated from the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "figureIndex = 1\n",
    "#Iterate through all layers\n",
    "for layer in model.layers:\n",
    "    plt.figure(figureIndex, figsize=(10,10)) \n",
    "    if 'conv' in layer.name:\n",
    "        weights, biases = layer.get_weights()\n",
    "        print(layer.name, weights.shape)\n",
    "        \n",
    "        #scale filters        \n",
    "        f_min, f_max = weights.min(), weights.max()\n",
    "        filters = (weights - f_min) /(f_max - f_min)\n",
    "        \n",
    "        #iterate through all filters\n",
    "        num_filters = filters.shape[3]\n",
    "        nc = 8 \n",
    "        nr = math.ceil(num_filters/nc)\n",
    "        #Only plotting first index of filters\n",
    "        for i in range(num_filters):\n",
    "            plt.subplot(nr,nc,i+1)\n",
    "            filt = filters[:,:,:,i]\n",
    "            #Select channel\n",
    "            #print(filt[:,:,0].shape)\n",
    "            filt_chan = filt[:,:,0]\n",
    "            plt.imshow(filt_chan,cmap='gray_r',vmin=0)\n",
    "    figureIndex += 1   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the feature maps produced by the filters. Set up a model to visualise the filter maps. Take an image from the test sample to see how what its filter maps look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "#Use one of the test images\n",
    "\n",
    "img = train_images[0]\n",
    "\n",
    "#Display image we are going to run through our Convolutional Neural Net\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape image so it fits the input format\n",
    "img= img[np.newaxis, :,:,: ]\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(img)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "# -----------------------------------------------------------------------\n",
    "# Now let's display our representations\n",
    "# -----------------------------------------------------------------------\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    print(feature_map.shape)\n",
    "    if len(feature_map.shape) == 4:\n",
    "    \n",
    "        #-------------------------------------------\n",
    "        # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        #-------------------------------------------\n",
    "        n_features = feature_map.shape[-1]  # number of features in the feature map\n",
    "        size_y       = feature_map.shape[1]  # feature map shape (1, size_y, size_x, n_features)\n",
    "        size_x       = feature_map.shape[2]  # feature map shape (1, size_y, size_x, n_features)\n",
    "    \n",
    "        # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size_y, size_x * n_features))\n",
    "    \n",
    "        #-------------------------------------------------\n",
    "        # Postprocess the feature to be visually palatable\n",
    "        #-------------------------------------------------\n",
    "        for i in range(n_features):\n",
    "            x  = feature_map[0, :, :, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std ()\n",
    "            x *=  64\n",
    "            x += 128\n",
    "            x  = np.clip(x, 0, 255).astype('uint8')\n",
    "            display_grid[:, i * size_y : (i + 1) * size_x] = x # Tile each filter into a horizontal grid\n",
    "\n",
    "        #-----------------\n",
    "        # Display the grid\n",
    "        #-----------------\n",
    "\n",
    "        scale = 20. / n_features\n",
    "        plt.figure( figsize=(scale * n_features, scale) )\n",
    "        plt.title ( layer_name )\n",
    "        plt.grid  ( False )\n",
    "        plt.imshow( display_grid, aspect='auto', cmap='viridis' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercise: classification of the fashion MNIST dataset <a name=\"3.\"></a>\n",
    "\n",
    "This is another image dataset, but this time of fashion items. Again these are images of 28x28 pixels, black and white with pixel intensities ranging from 0 to 255.\n",
    "\n",
    "Load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the full training set into a validation set and a training set. Also scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to associate names with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format data so that it is suitable of a 2D convolutional neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "#after\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 2D neural net to classify the fashion data. Again, use whatever tools you think will help, many convolutional layers, maxpooling, dropout in the mlp..... etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
